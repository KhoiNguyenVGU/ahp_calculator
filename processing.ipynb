{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f74518c",
   "metadata": {},
   "source": [
    "# Preprocess Interview Dataset\n",
    "\n",
    "Transform the large Data - Base.csv into a simplified format matching sample-interview-data.csv structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a083ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (21256, 52)\n",
      "\n",
      "Column names:\n",
      "['Name', 'Age', 'Gender', 'Type of Graduation/Post Graduation', 'Marital status', 'Mode of interview given by candidate?', 'Pre Interview Check', 'Fluency in English based on introduction', 'Confidence based on Introduction (English)', 'Confidence based on the topic given  ', 'Confidence Based on the PPT Question', 'Confidence based on the sales scenario', 'Structured Thinking (In regional only)', 'Structured Thinking Based on the PPT Question', 'Structured Thinking( Call pitch)', 'Regional fluency based on the topic given  ', 'Regional fluency Based on the PPT Question', 'Regional fluency based on the  sales scenario', 'Does the candidate has mother tongue influence while speaking english.', 'Has acquaintance in Company and has spoken to him/her before applying?', 'Candidate Status', 'Last Fixed CTC (lakhs) ', 'Currently Employed', 'Experienced candidate - (Experience in months)', 'Experienced Candidate (Nature of work)', 'What was the type of Role?\\t', 'How many slides candidate have submitted in PPT?', 'Call-pitch Elements used during the call Sales Scenario', \"But, my child's exam are going on now, so we will keep the counselling session after the exams get over.(Time: Favourable pitch: Counsellor hype)\", 'Let me discuss it with my child', \"Sir being in education industry I know this is a marketing gimmick and at the end of the day you'll be selling the app.\", 'Role acceptance', 'Interview Verdict', 'Candidate is willing to relocate', 'Role Location to be given to the candidate', 'Comments', 'RedFlags Comments in Interview', 'Confidence based on Introduction (English).1', 'Confidence based on the topic given  .1', 'Confidence Based on the PPT Question.1', 'Confidence based on the sales scenario.1', 'Structured Thinking (In regional only).1', 'Structured Thinking Based on the PPT Question.1', 'Structured Thinking( Call pitch).1', 'Regional fluency based on the topic given  .1', 'Regional fluency Based on the PPT Question.1', 'Regional fluency based on the  sales scenario.1', 'Confidence Score', 'Structured Thinking Score', 'Regional Fluency Score', 'Total Score', 'Whether joined the company or not\\n']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Load the original dataset\n",
    "df = pd.read_csv(r'c:\\Users\\khoin\\OneDrive - student.vgu.edu.vn\\Desktop\\VGU\\General Study\\code\\ahp-calculator\\public\\Data - Base.csv')\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1fae0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed dataset shape: (21256, 8)\n",
      "\n",
      "First 5 rows:\n",
      "  candidate_name  confidence  communication  technical_skills  \\\n",
      "0         parida         9.2            3.3               7.8   \n",
      "1         shreej        10.0           10.0              10.0   \n",
      "2         ms6744         8.3            7.8              10.0   \n",
      "3         aswalu        10.0           10.0              10.0   \n",
      "4         aniket         8.3            7.8               5.6   \n",
      "\n",
      "   problem_solving  sales_ability  experience  final_result  \n",
      "0              7.8            9.0         7.1  Not Selected  \n",
      "1             10.0            9.0         6.2  Not Selected  \n",
      "2             10.0            9.0         5.9      Selected  \n",
      "3             10.0            9.0         6.0      Selected  \n",
      "4              5.6            9.0         5.8      Selected  \n"
     ]
    }
   ],
   "source": [
    "# Create simplified dataset\n",
    "processed_df = pd.DataFrame()\n",
    "\n",
    "# 1. Candidate Name\n",
    "processed_df['candidate_name'] = df['Name']\n",
    "\n",
    "# 2. Confidence (average of confidence scores, normalize to 0-10)\n",
    "# Use existing Confidence Score column\n",
    "processed_df['confidence'] = df['Confidence Score'] / 12 * 10  # Scale from 0-12 to 0-10\n",
    "\n",
    "# 3. Communication (based on fluency and regional fluency scores)\n",
    "processed_df['communication'] = df['Regional Fluency Score'] / 9 * 10  # Scale from 0-9 to 0-10\n",
    "\n",
    "# 4. Technical Skills (based on structured thinking)\n",
    "processed_df['technical_skills'] = df['Structured Thinking Score'] / 9 * 10  # Scale from 0-9 to 0-10\n",
    "\n",
    "# 5. Problem Solving (average of structured thinking aspects)\n",
    "processed_df['problem_solving'] = df['Structured Thinking Score'] / 9 * 10\n",
    "\n",
    "# 6. Sales Ability (based on sales scenario confidence)\n",
    "processed_df['sales_ability'] = df['Confidence based on the sales scenario'].map({\n",
    "    'Impactful - Good confidence throughout the sales scenario with energy': 9.0,\n",
    "    'Guarded Confidence - Confident in some areas and ordinary in others': 7.0,\n",
    "    'Nervous': 5.0,\n",
    "    'Low confidence and negative energy': 3.0\n",
    "}).fillna(7.0)\n",
    "\n",
    "# 7. Experience (convert experience months to a 1-10 scale)\n",
    "def experience_to_score(exp_text):\n",
    "    if pd.isna(exp_text) or 'Fresher' in str(exp_text):\n",
    "        return np.random.uniform(5.5, 6.5)  # Fresher\n",
    "    elif '6-11.99' in str(exp_text):\n",
    "        return np.random.uniform(6.5, 7.5)\n",
    "    elif '12-23.99' in str(exp_text):\n",
    "        return np.random.uniform(7.0, 8.0)\n",
    "    elif '24-35.99' in str(exp_text):\n",
    "        return np.random.uniform(7.5, 8.5)\n",
    "    elif '36-47.99' in str(exp_text):\n",
    "        return np.random.uniform(8.0, 9.0)\n",
    "    elif '48+' in str(exp_text):\n",
    "        return np.random.uniform(8.5, 9.5)\n",
    "    else:\n",
    "        return np.random.uniform(6.0, 7.0)\n",
    "\n",
    "processed_df['experience'] = df['Experienced candidate - (Experience in months)'].apply(experience_to_score)\n",
    "\n",
    "# 8. Final Result (map verdict to Selected/Not Selected)\n",
    "processed_df['final_result'] = df['Interview Verdict'].map({\n",
    "    'Premium Select': 'Selected',\n",
    "    'Borderline Select': 'Selected',\n",
    "    'Select': 'Selected',\n",
    "    'Reject': 'Not Selected',\n",
    "    'Borderline Reject': 'Not Selected'\n",
    "}).fillna('Not Selected')\n",
    "\n",
    "# Round numerical columns to 1 decimal place\n",
    "numerical_cols = ['confidence', 'communication', 'technical_skills', 'problem_solving', 'sales_ability', 'experience']\n",
    "for col in numerical_cols:\n",
    "    processed_df[col] = processed_df[col].round(1)\n",
    "\n",
    "print(f\"\\nProcessed dataset shape: {processed_df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(processed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc348a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "candidate_name      0\n",
      "confidence          0\n",
      "communication       0\n",
      "technical_skills    0\n",
      "problem_solving     0\n",
      "sales_ability       0\n",
      "experience          0\n",
      "final_result        0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Data statistics:\n",
      "         confidence  communication  technical_skills  problem_solving  \\\n",
      "count  21256.000000   21256.000000      21256.000000     21256.000000   \n",
      "mean       6.770662       5.935566          6.893630         6.893630   \n",
      "std        2.531081       3.271162          3.020813         3.020813   \n",
      "min        0.800000       0.000000          0.000000         0.000000   \n",
      "25%        5.800000       3.300000          5.600000         5.600000   \n",
      "50%        6.700000       5.600000          7.800000         7.800000   \n",
      "75%        9.200000      10.000000          8.900000         8.900000   \n",
      "max       10.000000      10.000000         10.000000        10.000000   \n",
      "\n",
      "       sales_ability    experience  \n",
      "count   21256.000000  21256.000000  \n",
      "mean        7.313323      6.397408  \n",
      "std         1.330624      0.874605  \n",
      "min         5.000000      5.500000  \n",
      "25%         7.000000      5.900000  \n",
      "50%         7.000000      6.200000  \n",
      "75%         9.000000      6.500000  \n",
      "max         9.000000      9.500000  \n",
      "\n",
      "\n",
      "Final result distribution:\n",
      "final_result\n",
      "Selected        14304\n",
      "Not Selected     6952\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(processed_df.isnull().sum())\n",
    "\n",
    "print(\"\\n\\nData statistics:\")\n",
    "print(processed_df.describe())\n",
    "\n",
    "print(\"\\n\\nFinal result distribution:\")\n",
    "print(processed_df['final_result'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a74f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Processed data saved to: c:\\Users\\khoin\\OneDrive - student.vgu.edu.vn\\Desktop\\VGU\\General Study\\code\\ahp-calculator\\public\\interview-data-processed.csv\n",
      "Total records: 21256\n",
      "\n",
      "Sample of saved data:\n",
      "  candidate_name  confidence  communication  technical_skills  \\\n",
      "0         parida         9.2            3.3               7.8   \n",
      "1         shreej        10.0           10.0              10.0   \n",
      "2         ms6744         8.3            7.8              10.0   \n",
      "3         aswalu        10.0           10.0              10.0   \n",
      "4         aniket         8.3            7.8               5.6   \n",
      "5         faizal         5.0            4.4               3.3   \n",
      "6         ravatn         8.3            7.8               6.7   \n",
      "7         gornal         6.7            3.3               5.6   \n",
      "8         Upkarr         5.8            4.4               5.6   \n",
      "9         moizju         7.5            5.6               8.9   \n",
      "\n",
      "   problem_solving  sales_ability  experience  final_result  \n",
      "0              7.8            9.0         7.1  Not Selected  \n",
      "1             10.0            9.0         6.2  Not Selected  \n",
      "2             10.0            9.0         5.9      Selected  \n",
      "3             10.0            9.0         6.0      Selected  \n",
      "4              5.6            9.0         5.8      Selected  \n",
      "5              3.3            7.0         6.4  Not Selected  \n",
      "6              6.7            9.0         6.2      Selected  \n",
      "7              5.6            7.0         6.2  Not Selected  \n",
      "8              5.6            5.0         6.0  Not Selected  \n",
      "9              8.9            7.0         6.0      Selected  \n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing values (if any)\n",
    "processed_df_clean = processed_df.dropna()\n",
    "\n",
    "# Save to public folder\n",
    "output_path = r'c:\\Users\\khoin\\OneDrive - student.vgu.edu.vn\\Desktop\\VGU\\General Study\\code\\ahp-calculator\\public\\interview-data-processed.csv'\n",
    "processed_df_clean.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Processed data saved to: {output_path}\")\n",
    "print(f\"Total records: {len(processed_df_clean)}\")\n",
    "print(f\"\\nSample of saved data:\")\n",
    "print(processed_df_clean.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01b7174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VERDICT DISTRIBUTION COMPARISON\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š ORIGINAL DATASET - 5-Level Verdicts:\n",
      "----------------------------------------------------------------------\n",
      "  Select..................................   9607 (45.20%)\n",
      "  Reject..................................   4250 (19.99%)\n",
      "  Borderline Select.......................   3500 (16.47%)\n",
      "  Premium Select..........................   1197 ( 5.63%)\n",
      "  Borderline Reject.......................    150 ( 0.71%)\n",
      "  Total...................................  21256 (100.00%)\n",
      "\n",
      "ðŸ“Š PROCESSED DATASET - 2-Level Classification:\n",
      "----------------------------------------------------------------------\n",
      "  Selected................................  14304 (67.29%)\n",
      "  Not Selected............................   6952 (32.71%)\n",
      "  Total...................................  21256 (100.00%)\n",
      "\n",
      "âœ… Processing Summary:\n",
      "----------------------------------------------------------------------\n",
      "  Original records:         21256\n",
      "  After cleaning:           21256\n",
      "  Records removed:              0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Distribution comparison: Original vs Processed\n",
    "print(\"=\" * 70)\n",
    "print(\"VERDICT DISTRIBUTION COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nðŸ“Š ORIGINAL DATASET - 5-Level Verdicts:\")\n",
    "print(\"-\" * 70)\n",
    "original_verdicts = df['Interview Verdict'].value_counts()\n",
    "for verdict, count in original_verdicts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {verdict:.<40} {count:>6} ({percentage:>5.2f}%)\")\n",
    "print(f\"  {'Total':.<40} {len(df):>6} (100.00%)\")\n",
    "\n",
    "print(\"\\nðŸ“Š PROCESSED DATASET - 2-Level Classification:\")\n",
    "print(\"-\" * 70)\n",
    "processed_verdicts = processed_df_clean['final_result'].value_counts()\n",
    "for verdict, count in processed_verdicts.items():\n",
    "    percentage = (count / len(processed_df_clean)) * 100\n",
    "    print(f\"  {verdict:.<40} {count:>6} ({percentage:>5.2f}%)\")\n",
    "print(f\"  {'Total':.<40} {len(processed_df_clean):>6} (100.00%)\")\n",
    "\n",
    "print(\"\\nâœ… Processing Summary:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"  Original records:        {len(df):>6}\")\n",
    "print(f\"  After cleaning:          {len(processed_df_clean):>6}\")\n",
    "print(f\"  Records removed:         {len(df) - len(processed_df_clean):>6}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
